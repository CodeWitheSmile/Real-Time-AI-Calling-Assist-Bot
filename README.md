ğŸ¤– Real-Time Customer Support Agent Assist & Resolution Bot
A voice-driven AI assistant built with Streamlit, SpeechRecognition, NLP, and TTS, designed to help resolve customer queries in real-time by detecting intent and responding naturally.

ğŸ” Features
ğŸ™ï¸ Voice Input: Record queries directly from a microphone.

ğŸ“ Speech-to-Text: Transcribe audio using pre-trained ASR.

ğŸ¤– Intent Detection: Match input against predefined intents using Sentence-BERT.

ğŸ’¬ Dynamic Responses: Generate context-based replies.

ğŸ—£ï¸ Text-to-Speech: Convert replies to human-like speech.

ğŸ“œ Conversation Logging: Store user interactions with timestamps.

ğŸ§  Multimodal Ready: Extendable to include audio classification or emotion detection.

ğŸ§± Project Structure
Project/
â”œâ”€â”€ app1.py                     # Main Streamlit interface
â”œâ”€â”€ asr.py                      # Audio recording and transcription
â”œâ”€â”€ config.py                   # Configurations for paths and model names
â”œâ”€â”€ intent_detector.py          # Intent matching using Sentence-BERT
â”œâ”€â”€ response.py                 # Rule-based response generator
â”œâ”€â”€ run_bot.py                  # Will run recording, transcription, intent detection and AI voive reply in terminal
â”œâ”€â”€ speech_AI_Voice.py          # Text-to-Speech engine
â”œâ”€â”€ audio_classifier.py         # (Optional) Audio emotion classification
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ intent_data.json        # Predefined intents and sample utterances
â”‚   â””â”€â”€ conversations.jsonl     # Log of past user-bot conversations
ğŸ› ï¸ Setup Instructions
âœ… 1. Clone the Repository
git clone https://github.com/CodeWitheSmile/Real-Time-AI-Calling-Assist-Bot.git
cd Real-Time-AI-Calling-Assist-Bot

âœ… 2. Create Virtual Environment & Install Dependencies

python -m venv venv
source venv/bin/activate      # On Windows use: venv\Scripts\activate
pip install -r requirements.txt
If requirements.txt is not available, install manually:
pip install streamlit sentence-transformers sounddevice scipy SpeechRecognition pyttsx3

âœ… 3. Prepare Data
Ensure the following files are in place:

data/intent_data.json: Contains your training examples and intents.

data/conversations.jsonl: (Auto-created) For logging chats.

Sample intent_data.json format:

[
  {
    "intent": "greeting",
    "examples": ["hello", "hi", "hey", "good morning"]
  },
  {
    "intent": "goodbye",
    "examples": ["bye", "see you", "good night"]
  }
]
ğŸš€ Running the App
bash
Copy
Edit
streamlit run app1.py
ğŸ’¡ How It Works
ğŸ”Š Record Audio:
Captures a few seconds of voice input when "ğŸ™ï¸ Speak" button is clicked.

ğŸ“ Transcription:
Audio is passed to a speech recognition model which returns a clean transcript.

ğŸ§  Intent Detection:
The transcript is encoded with Sentence-BERT and compared to pre-trained intent vectors.

ğŸ’¬ Response:
A rule-based engine returns a contextually appropriate reply, and it's vocalized via TTS.

ğŸ““ Log:
All conversations are appended to conversations.jsonl for analysis.

ğŸ“Œ Example Interaction
You: "I need help with my internet connection"
Bot: "Sure! Can you tell me if your router is showing any red lights?"

ğŸ”§ Optional Extensions
ğŸ”ˆ audio_classifier.py: Add emotion-aware responses.

ğŸ“Š Build a dashboard to show metrics like intent frequency, satisfaction scores, etc.

ğŸŒ Multilingual support using translation APIs.

ğŸ§‘â€ğŸ’» Authors
Akshay Katoch

Final Year AI/ML Project â€” Nebula.AI

Inspired by real-world voice-driven customer support systems.
